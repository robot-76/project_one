{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from mmdet.core import bbox_xyxy_to_cxcywh\n",
    "from .transformer import inverse_sigmoid\n",
    "\n",
    "\n",
    "class DnQueryGenerator:\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_queries,\n",
    "                 hidden_dim,\n",
    "                 num_classes,\n",
    "                 noise_scale=dict(label=0.5, box=0.4),\n",
    "                 group_cfg=dict(\n",
    "                     dynamic=True, num_groups=None, num_dn_queries=None)):\n",
    "        super(DnQueryGenerator, self).__init__()\n",
    "        self.num_queries = num_queries\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.label_noise_scale = noise_scale['label']\n",
    "        self.box_noise_scale = noise_scale['box']\n",
    "        self.dynamic_dn_groups = group_cfg.get('dynamic', False)\n",
    "        if self.dynamic_dn_groups:\n",
    "            assert 'num_dn_queries' in group_cfg, \\\n",
    "                'num_dn_queries should be set when using ' \\\n",
    "                'dynamic dn groups'\n",
    "            self.num_dn = group_cfg['num_dn_queries']\n",
    "        else:\n",
    "            assert 'num_groups' in group_cfg, \\\n",
    "                'num_groups should be set when using ' \\\n",
    "                'static dn groups'\n",
    "            self.num_dn = group_cfg['num_groups']\n",
    "        assert isinstance(self.num_dn, int) and self.num_dn >= 1, \\\n",
    "            f'Expected the num in group_cfg to have type int. ' \\\n",
    "            f'Found {type(self.num_dn)} '\n",
    "\n",
    "    def get_num_groups(self, group_queries=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            group_queries (int): Number of dn queries in one group.\n",
    "        \"\"\"\n",
    "        if self.dynamic_dn_groups:\n",
    "            assert group_queries is not None, \\\n",
    "                'group_queries should be provided when using ' \\\n",
    "                'dynamic dn groups'\n",
    "            if group_queries == 0:\n",
    "                num_groups = 1\n",
    "            else:\n",
    "                num_groups = self.num_dn // group_queries\n",
    "        else:\n",
    "            num_groups = self.num_dn\n",
    "        if num_groups < 1:\n",
    "            num_groups = 1\n",
    "        return int(num_groups)\n",
    "\n",
    "    def __call__(self,\n",
    "                 gt_bboxes,\n",
    "                 gt_labels=None,\n",
    "                 label_enc=None,\n",
    "                 img_metas=None):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            gt_bboxes (List[Tensor]): List of ground truth bboxes\n",
    "                of the image, shape of each (num_gts, 4).\n",
    "            gt_labels (List[Tensor]): List of ground truth labels\n",
    "                of the image, shape of each (num_gts,), if None,\n",
    "                TODO:noisy_label would be None.\n",
    "\n",
    "        Returns:\n",
    "            TODO\n",
    "        \"\"\"\n",
    "        # TODO: temp only support for CDN\n",
    "        # TODO: temp assert gt_labels is not None and label_enc is not None\n",
    "        if gt_labels is not None:\n",
    "            assert len(gt_bboxes) == len(gt_labels), \\\n",
    "                f'the length of provided gt_labels ' \\\n",
    "                f'{len(gt_labels)} should be equal to' \\\n",
    "                f' that of gt_bboxes {len(gt_bboxes)}'\n",
    "        assert gt_labels is not None \\\n",
    "               and label_enc is not None \\\n",
    "               and img_metas is not None  # TODO: adjust args\n",
    "        batch_size = len(gt_bboxes)\n",
    "\n",
    "        # convert bbox\n",
    "        gt_bboxes_list = []\n",
    "        for img_meta, bboxes in zip(img_metas, gt_bboxes):\n",
    "            img_h, img_w, _ = img_meta['img_shape']\n",
    "            factor = bboxes.new_tensor([img_w, img_h, img_w,\n",
    "                                        img_h]).unsqueeze(0)\n",
    "            bboxes_normalized = bbox_xyxy_to_cxcywh(bboxes) / factor\n",
    "            gt_bboxes_list.append(bboxes_normalized)\n",
    "        gt_bboxes = gt_bboxes_list\n",
    "\n",
    "        known = [torch.ones_like(labels) for labels in gt_labels]\n",
    "        known_num = [sum(k) for k in known]\n",
    "\n",
    "        num_groups = self.get_num_groups(int(max(known_num)))\n",
    "\n",
    "        unmask_bbox = unmask_label = torch.cat(known)\n",
    "        labels = torch.cat(gt_labels)\n",
    "        boxes = torch.cat(gt_bboxes)\n",
    "        batch_idx = torch.cat(\n",
    "            [torch.full_like(t.long(), i) for i, t in enumerate(gt_labels)])\n",
    "\n",
    "        known_indice = torch.nonzero(unmask_label + unmask_bbox)\n",
    "        known_indice = known_indice.view(-1)\n",
    "\n",
    "        known_indice = known_indice.repeat(2 * num_groups, 1).view(-1)\n",
    "        known_labels = labels.repeat(2 * num_groups, 1).view(-1)\n",
    "        known_bid = batch_idx.repeat(2 * num_groups, 1).view(-1)\n",
    "        known_bboxs = boxes.repeat(2 * num_groups, 1)\n",
    "        known_labels_expand = known_labels.clone()\n",
    "        known_bbox_expand = known_bboxs.clone()\n",
    "\n",
    "        if self.label_noise_scale > 0:\n",
    "            p = torch.rand_like(known_labels_expand.float())\n",
    "            chosen_indice = torch.nonzero(\n",
    "                p < (self.label_noise_scale * 0.5)).view(-1)\n",
    "            new_label = torch.randint_like(chosen_indice, 0, self.num_classes)\n",
    "            known_labels_expand.scatter_(0, chosen_indice, new_label)\n",
    "        single_pad = int(max(known_num))  # TODO\n",
    "\n",
    "        pad_size = int(single_pad * 2 * num_groups)\n",
    "        positive_idx = torch.tensor(range(\n",
    "            len(boxes))).long().cuda().unsqueeze(0).repeat(num_groups, 1)\n",
    "        positive_idx += (torch.tensor(range(num_groups)) * len(boxes) *\n",
    "                         2).long().cuda().unsqueeze(1)\n",
    "        positive_idx = positive_idx.flatten()\n",
    "        negative_idx = positive_idx + len(boxes)\n",
    "        if self.box_noise_scale > 0:\n",
    "            known_bbox_ = torch.zeros_like(known_bboxs)\n",
    "            known_bbox_[:, : 2] = \\\n",
    "                known_bboxs[:, : 2] - known_bboxs[:, 2:] / 2\n",
    "            known_bbox_[:, 2:] = \\\n",
    "                known_bboxs[:, :2] + known_bboxs[:, 2:] / 2\n",
    "\n",
    "            diff = torch.zeros_like(known_bboxs)\n",
    "            diff[:, :2] = known_bboxs[:, 2:] / 2\n",
    "            diff[:, 2:] = known_bboxs[:, 2:] / 2\n",
    "\n",
    "            rand_sign = torch.randint_like(\n",
    "                known_bboxs, low=0, high=2, dtype=torch.float32)\n",
    "            rand_sign = rand_sign * 2.0 - 1.0\n",
    "            rand_part = torch.rand_like(known_bboxs)\n",
    "            rand_part[negative_idx] += 1.0\n",
    "            rand_part *= rand_sign\n",
    "            known_bbox_ += \\\n",
    "                torch.mul(rand_part, diff).cuda() * self.box_noise_scale\n",
    "            known_bbox_ = known_bbox_.clamp(min=0.0, max=1.0)\n",
    "            known_bbox_expand[:, :2] = \\\n",
    "                (known_bbox_[:, :2] + known_bbox_[:, 2:]) / 2\n",
    "            known_bbox_expand[:, 2:] = \\\n",
    "                known_bbox_[:, 2:] - known_bbox_[:, :2]\n",
    "\n",
    "        m = known_labels_expand.long().to('cuda')\n",
    "        input_label_embed = label_enc(m)\n",
    "        input_bbox_embed = inverse_sigmoid(known_bbox_expand, eps=1e-3)\n",
    "\n",
    "        padding_label = torch.zeros(pad_size, self.hidden_dim).cuda()\n",
    "        padding_bbox = torch.zeros(pad_size, 4).cuda()\n",
    "\n",
    "        input_query_label = padding_label.repeat(batch_size, 1, 1)\n",
    "        input_query_bbox = padding_bbox.repeat(batch_size, 1, 1)\n",
    "\n",
    "        map_known_indice = torch.tensor([]).to('cuda')\n",
    "        if len(known_num):\n",
    "            map_known_indice = torch.cat(\n",
    "                [torch.tensor(range(num)) for num in known_num])\n",
    "            map_known_indice = torch.cat([\n",
    "                map_known_indice + single_pad * i\n",
    "                for i in range(2 * num_groups)\n",
    "            ]).long()\n",
    "        if len(known_bid):\n",
    "            input_query_label[(known_bid.long(),\n",
    "                               map_known_indice)] = input_label_embed\n",
    "            input_query_bbox[(known_bid.long(),\n",
    "                              map_known_indice)] = input_bbox_embed\n",
    "\n",
    "        tgt_size = pad_size + self.num_queries\n",
    "        attn_mask = torch.ones(tgt_size, tgt_size).to('cuda') < 0\n",
    "        # match query cannot see the reconstruct\n",
    "        attn_mask[pad_size:, :pad_size] = True\n",
    "        # reconstruct cannot see each other\n",
    "        for i in range(num_groups):\n",
    "            if i == 0:\n",
    "                attn_mask[single_pad * 2 * i:single_pad * 2 * (i + 1),\n",
    "                          single_pad * 2 * (i + 1):pad_size] = True\n",
    "            if i == num_groups - 1:\n",
    "                attn_mask[single_pad * 2 * i:single_pad * 2 *\n",
    "                          (i + 1), :single_pad * i * 2] = True\n",
    "            else:\n",
    "                attn_mask[single_pad * 2 * i:single_pad * 2 * (i + 1),\n",
    "                          single_pad * 2 * (i + 1):pad_size] = True\n",
    "                attn_mask[single_pad * 2 * i:single_pad * 2 *\n",
    "                          (i + 1), :single_pad * 2 * i] = True\n",
    "\n",
    "        dn_meta = {\n",
    "            'pad_size': pad_size,\n",
    "            'num_dn_group': num_groups,\n",
    "        }\n",
    "        return input_query_label, input_query_bbox, attn_mask, dn_meta\n",
    "\n",
    "\n",
    "class CdnQueryGenerator(DnQueryGenerator):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CdnQueryGenerator, self).__init__(*args, **kwargs)\n",
    "\n",
    "\n",
    "def build_dn_generator(dn_args):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        dn_args (dict):\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    if dn_args is None:\n",
    "        return None\n",
    "    type = dn_args.pop('type')\n",
    "    if type == 'DnQueryGenerator':\n",
    "        return DnQueryGenerator(**dn_args)\n",
    "    elif type == 'CdnQueryGenerator':\n",
    "        return CdnQueryGenerator(**dn_args)\n",
    "    else:\n",
    "        raise NotImplementedError(f'{type} is not supported yet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
