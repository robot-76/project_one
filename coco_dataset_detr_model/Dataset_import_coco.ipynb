{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import json\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segmentation': [[239.97,\n",
       "   260.24,\n",
       "   222.04,\n",
       "   270.49,\n",
       "   199.84,\n",
       "   253.41,\n",
       "   213.5,\n",
       "   227.79,\n",
       "   259.62,\n",
       "   200.46,\n",
       "   274.13,\n",
       "   202.17,\n",
       "   277.55,\n",
       "   210.71,\n",
       "   249.37,\n",
       "   253.41,\n",
       "   237.41,\n",
       "   264.51,\n",
       "   242.54,\n",
       "   261.95,\n",
       "   228.87,\n",
       "   271.34]],\n",
       " 'area': 2765.1486500000005,\n",
       " 'iscrowd': 0,\n",
       " 'image_id': 558840,\n",
       " 'bbox': [199.84, 200.46, 77.71, 70.88],\n",
       " 'category_id': 58,\n",
       " 'id': 156}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_train= \"./annotations/instances_train2017.json\"\n",
    "file = open(path)\n",
    "anns = json.load(file)\n",
    "anns.keys()\n",
    "anns['annotations'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=136.08s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.41s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.76s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=5.83s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "coco_root_train = os.path.join( \"./coco_dataset_test/train2017\")\n",
    "coco_root_val = os.path.join( \"./coco_dataset_test/val2017\")\n",
    "coco_root_test = os.path.join(\"./coco_dataset_test/test2017\")\n",
    "coco_root_unlabeled = os.path.join(\"./coco_dataset_test/unlabeled2017\")\n",
    "\n",
    "\n",
    "# transform to be applieds to the images\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    ToTensor(),\n",
    "    Resize((500,333))\n",
    "    ])\n",
    "\n",
    "# Function to create CocoDataset instances\n",
    "def create_coco_dataset(root, ann_file, transform=None):\n",
    "    return CocoDetection(root=root, annFile=ann_file, transform=transform)\n",
    "\n",
    "coco_dataset_train = create_coco_dataset(root=coco_root_train, ann_file=(\"./annotations/instances_train2017.json\"), transform=transform)\n",
    "coco_dataset_val = create_coco_dataset(root=coco_root_val, ann_file=(\"./annotations/instances_val2017.json\"), transform=transform)\n",
    "captions_coco_dataset_train = create_coco_dataset(root=coco_root_train, ann_file=(\"./annotations/captions_train2017.json\"), transform=transform)\n",
    "captions_coco_dataset_val = create_coco_dataset(root=coco_root_val, ann_file=(\"./annotations/captions_val2017.json\"), transform=transform)\n",
    "person_keypoint_coco_dataset_train = create_coco_dataset(root=coco_root_train, ann_file=(\"./annotations/person_keypoints_train2017.json\"), transform=transform)\n",
    "person_keypoint_coco_dataset_val = create_coco_dataset(root=coco_root_val, ann_file=(\"./annotations/person_keypoints_val2017.json\"), transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "# dataloader for each dataset\n",
    "dataloader_train = DataLoader(coco_dataset_train, batch_size=32, shuffle=True, num_workers=4)\n",
    "dataloader_val = DataLoader(coco_dataset_val, batch_size=32, shuffle=True, num_workers=4)\n",
    "#dataloader_test = DataLoader(coco_root_test, batch_size=32, shuffle=True, num_workers=4)\n",
    "#dataloader_unlabeled = DataLoader(coco_root_unlabeled, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "for batch in dataloader_train: \n",
    "    print(len(batch))\n",
    "    images, targets = batch #traget means batch of labels\n",
    "    \n",
    "#for batch in dataloader_val:\n",
    "    #images, targets = batch\n",
    "\n",
    "#for batch in dataloader_test:\n",
    "   # images, targets = batch\n",
    "    \n",
    "#for batch in dataloader_unlabeled:\n",
    "    #images, targets = batch\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show images and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, targets \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataloader_train\u001b[49m:\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m     38\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     39\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataloader_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define a simple CNN model for feature extraction\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 256)  # Adjust input size based on your image dimensions\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 128 * 16 * 16)  # Adjust input size based on your image dimensions\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define the transform to be applied to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # Add more transformations as needed\n",
    "])\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Set the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model for a few epochs (this is a simplified training loop)\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for images, targets in dataloader_train:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "\n",
    "# Feature extraction example (using the first batch of the dataloader)\n",
    "with torch.no_grad():\n",
    "    example_images, _ = next(iter(dataloader_train))\n",
    "    extracted_features = model(example_images)\n",
    "    print(\"Shape of extracted features:\", extracted_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## DETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(nn.Module):\n",
    "    def __init__(self, root, ann_file, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.ann_file = ann_file\n",
    "        self.coco = CocoDetection(root=root, annFile=ann_file, transform=transform)\n",
    "        self.coco_info = self.coco.coco\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, target = self.coco[idx]\n",
    "        img_id = self.coco_info.imgs[idx]\n",
    "        ann_ids = self.coco_info.getAnnIds(imgIds=img_id)\n",
    "        anns = self.coco_info.loadAnns(ann_ids)\n",
    "        return img, target, anns\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coco)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
