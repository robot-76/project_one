{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize image dataset (don't run this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have defined the build method as shown in the provided code\n",
    "\n",
    "# Set the image_set and args accordingly\n",
    "image_set = \"train\"\n",
    "coco_path = \"./coco_dataset_test\"\n",
    "\n",
    "# Create the dataset using the build method\n",
    "dataset = build(image_set, coco_path, strong_aug=True, fix_size=False)\n",
    "\n",
    "# Iterate over the dataset to print images and annotations\n",
    "for i in range(len(dataset)):\n",
    "    # Get the image and target (annotations)\n",
    "    image, target = dataset[i]\n",
    "    \n",
    "    # Convert image tensor to numpy array\n",
    "    image_np = image.permute(1, 2, 0).numpy()\n",
    "\n",
    "    # Plot the image\n",
    "    plt.imshow(image_np)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Image {i}')\n",
    "    plt.show()\n",
    "\n",
    "    # Print annotations\n",
    "    print(\"Annotations:\")\n",
    "    print(target)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show image (don't run this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have defined the build method as shown in the provided code\n",
    "\n",
    "# Set the image_set and args accordingly\n",
    "image_set = \"train\"\n",
    "coco_path = \"./coco_dataset_test\"\n",
    "\n",
    "# Create the dataset using the build method\n",
    "dataset = build(image_set, coco_path, strong_aug=True, fix_size=False)\n",
    "dataloader_train = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=0, collate_fn=utils.collate_fn)\n",
    "\n",
    "for batch in dataloader_train:\n",
    "    images, targets = batch\n",
    "    #targets =[ target.to(device) for target in targets]\n",
    "    #images = list(img.to(device) for img in images)\n",
    "    print(\"targets\",targets)\n",
    "     \n",
    "\n",
    "    print(F\"targets=\", targets)\n",
    "    print(F\"images=\", images)\n",
    "        # Convert image tensor to numpy array\n",
    "    # Iterate over the images in the NestedTensor\n",
    "    images_list = images.tensors\n",
    "    for i, image in enumerate(images_list):\n",
    "        # Get the image\n",
    "        \n",
    "        image_np = image.permute(1, 2, 0).numpy()\n",
    "\n",
    "        # Plot the image\n",
    "        plt.imshow(image_np)\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Image {i}')\n",
    "        plt.show()\n",
    "        \n",
    "    #for i, image in enumerate(images):\n",
    "        #print(f\"Shape of image {i}: {image.shape}\")\n",
    "        \n",
    "    #images_tensor = torch.stack(images)\n",
    "    #print(images_tensor.shape)\n",
    "    \n",
    "     # Get color images (assuming images are in RGB format)\n",
    "    #color_images = [F.to_pil_image(image.cpu()) for image in images]\n",
    "\n",
    "    # Display color images\n",
    "    #for i, color_image in enumerate(color_images):\n",
    "        #plt.imshow(color_image)\n",
    "        #plt.show()\n",
    "\n",
    "    # Access tensors (boxes, labels, image_ids, ids) for further processing\n",
    "    #for target in targets:\n",
    "        #Access target data, e.g., boxes, labels, etc.\n",
    "        #boxes = target[:, :4]\n",
    "        #labels = target[:, 4]\n",
    "        #image_ids = target[:, 5]\n",
    "        #ids = target[:, 6]\n",
    "        #print(boxes, labels, image_ids, ids)\n",
    "    break\n",
    "\n",
    "# Iterate over the dataset to print images and annotations\n",
    "for i in range(len(dataset)):\n",
    "    # Get the image and target (annotations)\n",
    "    image, target = dataset[i]\n",
    "    \n",
    "    # Convert image tensor to numpy array\n",
    "    image_np = image.permute(1, 2, 0).numpy()\n",
    "\n",
    "    # Plot the image\n",
    "    plt.imshow(image_np)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Image {i}')\n",
    "    plt.show()\n",
    "\n",
    "    # Print annotations\n",
    "    print(\"Annotations:\")\n",
    "    print(target)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Pretrain resnet50 Model (don't run this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Define your arguments\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.backbone = \"resnet50\"  # or any other supported backbone\n",
    "        self.lr_backbone = 0.1  # example learning rate for backbone, adjust as needed\n",
    "        self.masks = False  # whether to include masks in the output\n",
    "        self.num_feature_levels = 1  # number of feature levels, adjust as needed\n",
    "        self.dilation = False  # whether to use dilation in backbone\n",
    "        self.hidden_dim = 256  # hidden dimension for transformer\n",
    "        self.position_embedding = \"sine\"  # type of position embedding to use\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Build the backbone model\n",
    "model =build_backbone(args).to(device)\n",
    "\n",
    "# Assuming you have input data 'input_data', pass it through the model\n",
    "# input_data should be a NestedTensor, which is a tensor with an associated mask\n",
    "# Example usage assuming input_data is properly defined\n",
    "#output = model(nested_images)\n",
    "\n",
    "with torch.no_grad():\n",
    "    all_extracted_features = []\n",
    "    all_outputs = []\n",
    "\n",
    "    for batch in dataloader_train:\n",
    "        images, targets = batch\n",
    "        targets = [target.to(device) for target in targets]\n",
    "        images = [img.to(device) for img in images]\n",
    "        #print(\"shape of images\",images[0].shape)\n",
    "        #for img in images:\n",
    "            #print(img.shape)\n",
    "            #break\n",
    "        mask = [torch.ones_like(img) for img in images]\n",
    "        nested_images = nested_tensor_from_tensor_list(images).to(device)\n",
    "        output,extracted_features = model(nested_images)\n",
    "        #print(\"shape of extracted_features\")\n",
    "        #for img in extracted_features:\n",
    "            #print(img.shape)\n",
    "            #break\n",
    "        \n",
    "        #print(\"shape of output\")\n",
    "        #for img in output:\n",
    "            #for i in img.tensors:\n",
    "                #print(i.shape)\n",
    "                #break\n",
    "            \n",
    "        #all_extracted_features.append(extracted_features.detach())\n",
    "         # Append the output and extracted features to the lists\n",
    "        all_outputs.append(output)\n",
    "        all_extracted_features.append(extracted_features)\n",
    "            # Clear the memory\n",
    "        del images, targets, output, extracted_features\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Save the lists of outputs and extracted features\n",
    "    torch.save(all_outputs, os.path.join(os.getcwd(), 'all_outputs.pt'))\n",
    "    torch.save(all_extracted_features, os.path.join(os.getcwd(), 'all_extracted_features.pt'))\n",
    "        \n",
    "    #print(\"shape of image\",images)\n",
    "    # Concatenate features from all batches\n",
    "    #all_extracted_features = torch.cat(all_extracted_features, dim=0)\n",
    "\n",
    "#print(\"Shape of all extracted features:\", all_extracted_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Load the lists of outputs and extracted features in cpu memory\n",
    "all_outputs = torch.load(os.path.join(os.getcwd(), 'all_outputs.pt'), map_location='cpu')\n",
    "all_extracted_features = torch.load(os.path.join(os.getcwd(), 'all_extracted_features.pt'), map_location='cpu')\n",
    "\n",
    "# Now you can use all_outputs and all_extracted_features in your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for i, batch in enumerate(all_extracted_features):\n",
    "    for j, tensor in enumerate(batch):\n",
    "        print(f\"Shape of tensor {j} in batch {i}: {tensor.shape}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"shape of all_outputs\",all_extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"shape of all_outputs\",all_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape All Extracted Feature (don't run this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "reshaped_features = []\n",
    "\n",
    "for batch in all_extracted_features:\n",
    "    reshaped_batch = [tensor.permute(2, 3, 0, 1).contiguous().view(-1, *tensor.shape[:2]) for tensor in batch]\n",
    "    reshaped_features.append(reshaped_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for i, batch in enumerate(reshaped_features):\n",
    "    for j, tensor in enumerate(batch):\n",
    "        print(f\"Shape of tensor {j} in batch {i}: {tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize encoder layer output (don't run this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "encoder_layer = TransformerEncoderLayer(d_model=256, nhead=8, dim_feedforward=2048, dropout=0.1, activation=\"relu\", normalize_before=False)\n",
    "\n",
    "# Assume reshaped_features is your list of reshaped image features\n",
    "for i, batch in enumerate(reshaped_features):\n",
    "    for j, src in enumerate(batch):\n",
    "        \n",
    "        # Pass the tensor through the encoder layer\n",
    "        output = encoder_layer(src)\n",
    "\n",
    "        # Print the output\n",
    "        print(f\"Output of tensor {j} in batch {i}: {output}\")\n",
    "                # Print the shape of the output\n",
    "        print(f\"Shape of output: {output.shape}\")       \n",
    "        \n",
    "\n",
    "for i in range(output.shape[1]):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(output.detach().numpy()[i], cmap='hot', interpolation='nearest')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
